{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d7181559",
   "metadata": {},
   "source": [
    "2247255\n",
    "\n",
    "VIBISHNA.B\n",
    "\n",
    "2247255\n",
    "\n",
    "LAB-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f11b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd35913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gaussian', 'poisson', 'random', 'saltandpepper', 'speckle']\n"
     ]
    }
   ],
   "source": [
    "#Data Loader\n",
    "train_path='C:/Users/VIBISHNA/Downloads/noisedata/train'\n",
    "test_path='C:/Users/VIBISHNA/Downloads/noisedata/test'\n",
    "train_loader=DataLoader(torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "                       batch_size=100,shuffle=True)\n",
    "test_loader=DataLoader(torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "                       batch_size=100,shuffle=True)\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1]for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00db701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=8):\n",
    "        super(ConvNet,self).__init__()\n",
    "        #Output\n",
    "        #(w-f+2P)/s)+1\n",
    "        \n",
    "        #Input Shape =(100,3,150,150)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        #Input Shape =(100,3,150,150)\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #self.bn2=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu2=nn.ReLU()\n",
    "        \n",
    "        #Input Shape =(100,3,150,150)\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        \n",
    "        self.fc=nn.Linear(in_features=32*75*75,out_features=num_classes)\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        output=self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e8a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=8).to(device)\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "num_epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "711bbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 25\n",
      "Total test images: 15\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Define the file extensions you want to include\n",
    "allowed_extensions = ['jpg', 'jpeg', 'png', 'bmp', 'gif']  # Add any other formats you want\n",
    "\n",
    "# Count training images\n",
    "train_count = sum(len(glob.glob(train_path + f'/**/*.{ext}', recursive=True)) for ext in allowed_extensions)\n",
    "\n",
    "# Count test images\n",
    "test_count = sum(len(glob.glob(test_path + f'/**/*.{ext}', recursive=True)) for ext in allowed_extensions)\n",
    "\n",
    "print(\"Total training images:\", train_count)\n",
    "print(\"Total test images:\", test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4afd3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: tensor(56.5018) Train Accuracy 0.12 Test accuracy: 0.2\n",
      "Epoch 1 Train loss: tensor(432.8927) Train Accuracy 0.28 Test accuracy: 0.2\n",
      "Epoch 2 Train loss: tensor(552.6454) Train Accuracy 0.4 Test accuracy: 0.2\n",
      "Epoch 3 Train loss: tensor(791.4326) Train Accuracy 0.32 Test accuracy: 0.26666666666666666\n",
      "Epoch 4 Train loss: tensor(485.8346) Train Accuracy 0.4 Test accuracy: 0.26666666666666666\n",
      "Epoch 5 Train loss: tensor(453.8187) Train Accuracy 0.24 Test accuracy: 0.3333333333333333\n",
      "Epoch 6 Train loss: tensor(403.5342) Train Accuracy 0.44 Test accuracy: 0.4\n",
      "Epoch 7 Train loss: tensor(326.8674) Train Accuracy 0.4 Test accuracy: 0.4\n",
      "Epoch 8 Train loss: tensor(146.4740) Train Accuracy 0.52 Test accuracy: 0.3333333333333333\n",
      "Epoch 9 Train loss: tensor(251.7201) Train Accuracy 0.52 Test accuracy: 0.2\n",
      "Epoch 10 Train loss: tensor(135.9076) Train Accuracy 0.6 Test accuracy: 0.2\n",
      "Epoch 11 Train loss: tensor(130.2379) Train Accuracy 0.56 Test accuracy: 0.26666666666666666\n",
      "Epoch 12 Train loss: tensor(139.5645) Train Accuracy 0.6 Test accuracy: 0.26666666666666666\n",
      "Epoch 13 Train loss: tensor(167.8080) Train Accuracy 0.68 Test accuracy: 0.26666666666666666\n",
      "Epoch 14 Train loss: tensor(191.2715) Train Accuracy 0.52 Test accuracy: 0.3333333333333333\n",
      "Epoch 15 Train loss: tensor(124.6177) Train Accuracy 0.56 Test accuracy: 0.3333333333333333\n",
      "Epoch 16 Train loss: tensor(109.8112) Train Accuracy 0.64 Test accuracy: 0.3333333333333333\n",
      "Epoch 17 Train loss: tensor(68.9187) Train Accuracy 0.76 Test accuracy: 0.26666666666666666\n",
      "Epoch 18 Train loss: tensor(99.0939) Train Accuracy 0.72 Test accuracy: 0.3333333333333333\n",
      "Epoch 19 Train loss: tensor(33.1299) Train Accuracy 0.8 Test accuracy: 0.3333333333333333\n",
      "Epoch 20 Train loss: tensor(43.8341) Train Accuracy 0.76 Test accuracy: 0.3333333333333333\n",
      "Epoch 21 Train loss: tensor(50.4108) Train Accuracy 0.76 Test accuracy: 0.4\n",
      "Epoch 22 Train loss: tensor(14.8825) Train Accuracy 0.88 Test accuracy: 0.4\n",
      "Epoch 23 Train loss: tensor(66.8177) Train Accuracy 0.68 Test accuracy: 0.4\n",
      "Epoch 24 Train loss: tensor(27.0557) Train Accuracy 0.76 Test accuracy: 0.5333333333333333\n",
      "Epoch 25 Train loss: tensor(56.2711) Train Accuracy 0.84 Test accuracy: 0.6666666666666666\n",
      "Epoch 26 Train loss: tensor(97.5451) Train Accuracy 0.76 Test accuracy: 0.6\n",
      "Epoch 27 Train loss: tensor(64.1033) Train Accuracy 0.76 Test accuracy: 0.6\n",
      "Epoch 28 Train loss: tensor(65.8075) Train Accuracy 0.68 Test accuracy: 0.6\n",
      "Epoch 29 Train loss: tensor(30.3754) Train Accuracy 0.84 Test accuracy: 0.4666666666666667\n",
      "Epoch 30 Train loss: tensor(32.6665) Train Accuracy 0.88 Test accuracy: 0.4666666666666667\n",
      "Epoch 31 Train loss: tensor(12.5188) Train Accuracy 0.84 Test accuracy: 0.4666666666666667\n",
      "Epoch 32 Train loss: tensor(6.3622) Train Accuracy 0.96 Test accuracy: 0.5333333333333333\n",
      "Epoch 33 Train loss: tensor(114.6012) Train Accuracy 0.76 Test accuracy: 0.6\n",
      "Epoch 34 Train loss: tensor(2.4096) Train Accuracy 0.96 Test accuracy: 0.7333333333333333\n",
      "Epoch 35 Train loss: tensor(24.7446) Train Accuracy 0.84 Test accuracy: 0.6\n",
      "Epoch 36 Train loss: tensor(17.6980) Train Accuracy 0.92 Test accuracy: 0.8\n",
      "Epoch 37 Train loss: tensor(52.5762) Train Accuracy 0.88 Test accuracy: 0.6666666666666666\n",
      "Epoch 38 Train loss: tensor(5.2385) Train Accuracy 0.96 Test accuracy: 0.6666666666666666\n",
      "Epoch 39 Train loss: tensor(29.9084) Train Accuracy 0.8 Test accuracy: 0.6\n",
      "Epoch 40 Train loss: tensor(11.1320) Train Accuracy 0.88 Test accuracy: 0.6666666666666666\n",
      "Epoch 41 Train loss: tensor(4.8510) Train Accuracy 0.96 Test accuracy: 0.6666666666666666\n",
      "Epoch 42 Train loss: tensor(3.7793) Train Accuracy 0.96 Test accuracy: 0.8\n",
      "Epoch 43 Train loss: tensor(1.8508) Train Accuracy 0.96 Test accuracy: 0.6666666666666666\n",
      "Epoch 44 Train loss: tensor(1.7081) Train Accuracy 0.96 Test accuracy: 0.8666666666666667\n",
      "Epoch 45 Train loss: tensor(11.7588) Train Accuracy 0.92 Test accuracy: 0.8\n",
      "Epoch 46 Train loss: tensor(3.8434) Train Accuracy 0.92 Test accuracy: 0.9333333333333333\n",
      "Epoch 47 Train loss: tensor(2.5666) Train Accuracy 0.96 Test accuracy: 0.8\n",
      "Epoch 48 Train loss: tensor(0.0381) Train Accuracy 1.0 Test accuracy: 0.8\n",
      "Epoch 49 Train loss: tensor(0.0493) Train Accuracy 1.0 Test accuracy: 0.7333333333333333\n",
      "Overall Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "\n",
    "    print('Epoch ' + str(epoch) + ' Train loss: ' + str(train_loss) + ' Train Accuracy ' + str(train_accuracy) + ' Test accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best.model')\n",
    "        best_accuracy = test_accuracy\n",
    "print('Overall Test Accuracy: ' + str(best_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50de30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet1_1  \n",
    "import torch.functional as F\n",
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10b4b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path='C:/Users/VIBISHNA/Downloads/noisedata/pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd321786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc): Linear(in_features=180000, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=torch.load('best.model')\n",
    "model=ConvNet(num_classes=8)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11413032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path, transformer):\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    # Check and convert to RGB if image has 4 channels\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    image_tensor = transformer(image).float()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor = image_tensor.cuda()\n",
    "    \n",
    "    # Add a batch size dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    input = Variable(image_tensor)\n",
    "    output = model(input)\n",
    "    index = output.data.numpy().argmax()\n",
    "    pred = classes[index]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ecb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Define the allowed image extensions\n",
    "allowed_extensions = ['jpg', 'jpeg', 'png', 'bmp', 'gif']  # Add any other formats you want\n",
    "\n",
    "# Use glob to find all image files with allowed extensions\n",
    "images_path = [file for ext in allowed_extensions for file in glob.glob(pred_path + f'/*.{ext}')]\n",
    "\n",
    "# Now, images_path contains the paths of all image files with allowed extensions in pred_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d33bae95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/VIBISHNA/Downloads/noisedata/pred\\\\g1.jpg',\n",
       " 'C:/Users/VIBISHNA/Downloads/noisedata/pred\\\\image9.jpg',\n",
       " 'C:/Users/VIBISHNA/Downloads/noisedata/pred\\\\r3.jpg',\n",
       " 'C:/Users/VIBISHNA/Downloads/noisedata/pred\\\\sp2.jpg',\n",
       " 'C:/Users/VIBISHNA/Downloads/noisedata/pred\\\\spe1.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39aee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "352aeaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred\\\\g1.jpg': 'gaussian',\n",
       " 'pred\\\\image9.jpg': 'poisson',\n",
       " 'pred\\\\r3.jpg': 'random',\n",
       " 'pred\\\\sp2.jpg': 'saltandpepper',\n",
       " 'pred\\\\spe1.jpg': 'speckle'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
